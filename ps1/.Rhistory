# load shape is a vector of relative availability for the measure--fractions of peak (in time)
# retail.elec is either a vector of prices or a single value
timesteps <- length(LMP)
if(length(nbt.threshold==1)){nbt.threshold <- matrix(nbt.threshold,nrow=timesteps)}
if(length(retail.elec==1)){retail.elec <- matrix(retail.elec,nrow=timesteps)}
if(length(load.shape)!=timesteps){stop("load shape different length than lmp")}
potential <- potential*load.shape
# make dr payment matrix with zeroes if < nbt and lMP if > nbt.
dr.payment <- matrix(data=0,nrow=timesteps)
pass.nbt <- which(LMP>=nbt.threshold)
fail.nbt <- which(LMP<nbt.threshold)
dr.payment[pass.nbt]<-LMP[pass.nbt]
if(only.during.nbt){retail.elec[fail.nbt]<-0}
dr.rev <- dr.payment*potential
e.save <- retail.elec*potential
tot <- dr.rev + e.save
out<-data.frame(dr.rev=dr.rev,e.save=e.save,tot=tot)
} #end function dr.payment
getCAISObids(startdate=20120101,enddate=20120102)->bids
rstudio::viewData(bids)
getCAISObids
getCAISObids(startdate=20120101,enddate=20120102,market="RTM")->bidr
names(bidr)
hist(bidr$STARTTIME)
class(bidr.STARTTIME)
class(bidr$STARTTIME)
hist(as.numeric((bidr$STARTTIME))
)
head(bidr)
read.csv("Downloads/ladb-test-results-final.csv")->t
names(t)
require(plyr)
tt <- ddply(.data=t, .variables=c(product_name, date_began), .fun=summary, srt=mean(solar.runtime.measured))
tt <- ddply(.data=t, .variables=c("product_name", "date_began"), .fun=summary, srt=mean(solar.runtime.measured))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar.runtime.measured))
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean("solar.runtime.measured"))
rstudio::viewData(tt)
warnings()
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar.runtime.measured))
tt <- ddply(.data=t, .variables=c("product_name", "date_began"), summarize, srt=mean(solar.runtime.measured))
names(t)
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar_runtime_measured))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n=count(solar_runtime_measured, na.rm=TRUE))
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n=count(solar_runtime_measured))
count(c(1,2,3,4))
length(c(1,2,3,4))
?length
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n=length(solar_runtime_measured))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began, setting), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n.srt=length(solar_runtime_measured), lm=mean(runtime_flux_70))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began, setting), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n.srt=length(solar_runtime_measured), lm=mean(runtime_flux_70, na.rm=TRUE))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began, setting), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n.srt=length(solar_runtime_measured), lm.run=mean(runtime_flux_70, na.rm=TRUE), lm.nom=mean(nominal_lumin_flux), na.rm=TRUE)
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began, setting), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n.srt=length(solar_runtime_measured), lm.run=mean(runtime_flux_70, na.rm=TRUE), lm.nom=mean(nominal_lumin_flux, na.rm=TRUE))
rstudio::viewData(tt)
min(NaN, 2)
min(NaN, 2, na.rm=TRUE)
tt$lm <- min(lm.run, lm.nom, na.rm=TRUE)
tt$lm <- min(tt$lm.run, tt$lm.nom, na.rm=TRUE)
rstudio::viewData(tt)
tt$lm <- min(tt$lm.run, tt$lm.nom)
hist(tt$lm)
?min
min(c(1,2,3,4), c(2,3,4,5))
tt$lm <- pmin(tt$lm.run, tt$lm.nom, na.rm=TRUE)
rstudio::viewData(tt)
tt$lmhr <- tt$lm*tt$srt
hist(tt$lmhr)
plot(ecdf(tt$lmhr))
setwd("~/Google Drive/ERG/Classes/ARE213/are213/ps1")
library(foreign) #this is to read in Stata data
library(Hmisc)
library(psych)
data <- read.dta("ps1.dta")
require(Hmisc)
install.packages(c("Hmisc", "psych"))
library(foreign) #this is to read in Stata data
library(Hmisc)
library(psych)
data <- read.dta("ps1.dta")
print(nrow(ps1.data))
## Problem 1a: Fix miss
ps1.data <- read.dta("ps1.dta") #changed name of object from "data" to avoid ambiguity issues since "data" is often embedded in functions as a general object
print(nrow(ps1.data))
## Problem 1a: Fix mis
ps1.data <- subset (ps1.data, (cardiac != 9) & (lung != 9) & (diabetes !=9) & (herpes !=9) & (chyper !=9) & (phyper !=9) & (pre4000 !=9) & (preterm !=9) & (tobacco !=9) & (cigar !=99) & (cigar6 !=6) & (alcohol !=9) & (drink !=99) & (drink5 !=5) & (wgain !=99))
print(nrow(ps1.data)) #number of records remaining after cleaning
?subset
attach(ps1.data)
detach(name=ps1.data)
wgain %in% names(ps1.data)
"wgain" %in% names(ps1.data)
?match
match("wgain", names(ps1.data))
match("alcohol", names(ps1.data))
full.record.flag <- which(ps1.data$cardiac != 9 & ps1.data$lung != 9 & ps1.data$diabetes !=9 & ps1.data$herpes != 9 & ps1.data$chyper != 9 & ps1.data$phyper != 9 & ps1.data$pre4000 !=9 & ps1.data$preterm != 9 & ps1.data$tobacco != 9 & ps1.data$cigar != 99 & ps1.data$cigar6 !=6 & ps1.data$alcohol != 9 & ps1.data$drink != 99 & ps1.data$drink5 !=5 & ps1.data$wgain !=99)
head(full.record.flag)
ps1.data$full.record <- FALSE # initialize column as F
ps1.data$full.record[full.record.flag] <- TRUE #reassign level to T for full records
head(ps1.data)
View(ps1.data)
ps1.data.clean <- subset (ps1.data, full.record == TRUE)
ps1.data <- read.dta("ps1.dta") #changed name of object from "data" to avoid ambiguity issues since "data" is often embedded in functions as a general object
print(nrow(ps1.data))
## Problem 1a: Fix missing values
## The following are the error codes for each of the 15 variables that need fixing:
# cardiac: 9
# lung: 9
# diabetes: 9
# herpes: 9
# chyper: 9
# phyper: 9
# pre4000: 9
# preterm: 9
# tobacco: 9
# cigar: 99
# cigar6: 6
# alcohol: 9
# drink: 99
# drink5: 5
# wgain: 99
# Identify which records have full data, then add a column to indicate full records or not.
full.record.flag <- which(ps1.data$cardiac != 9 & ps1.data$lung != 9 & ps1.data$diabetes !=9 & ps1.data$herpes != 9 & ps1.data$chyper != 9 & ps1.data$phyper != 9 & ps1.data$pre4000 !=9 & ps1.data$preterm != 9 & ps1.data$tobacco != 9 & ps1.data$cigar != 99 & ps1.data$cigar6 !=6 & ps1.data$alcohol != 9 & ps1.data$drink != 99 & ps1.data$drink5 !=5 & ps1.data$wgain !=99)
ps1.data$full.record <- FALSE # initialize column as F
ps1.data$full.record[full.record.flag] <- TRUE #reassign level to T for full records
ps1.data.clean <- subset (ps1.data, full.record == TRUE)
summarytable<-print(describe(ps1.data.clean, skew=FALSE, ranges=FALSE))
ps1.data.missingvalues <- subset(ps1.data, full.record == FALSE)
require(gdata)
install.packages(gdata)
install.packages("gdata")
aggregate.table(ps1.data, full.record, FUN="mean")
require(gdata)
aggregate.table(ps1.data, full.record, FUN="mean")
aggregate.table(ps1.data, "full.record", FUN="mean")
aggregate.table(ps1.data, "full.record", FUN="mean")
write.csv(ps1.data.clean, file = "ps1dataclean.csv")
?compare
nalysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .full.record, summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps))
require(ddply)
require(plyr)
nalysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .full.record, summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps))
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps))
View(ps1.compare.records)
# compare records on things that matter for this analysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
mean.cigar = mean(cigar),
sd.cigar = sd(cigar))
View(ps1.compare.records)
hist(ps1.data.missingvalues$cigar)
# compare records on things that matter for this analysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar)
)
View(ps1.compare.records)
?quantile
# compare records on things that matter for this analysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar),
per25.cigar = quantile(cigar,.25, na.rm = TRUE)
)
View(ps1.compare.records)
# compare records on things that matter for this analysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar),
per25.cigar = quantile(cigar,.25, na.rm = TRUE),
per75.cigar = quantile(cigar,.75, na.rm = TRUE),
per90.cigar = quantile(cigar,.90, na.rm = TRUE),
)
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar),
per25.cigar = quantile(cigar,.25, na.rm = TRUE),
per75.cigar = quantile(cigar,.75, na.rm = TRUE),
per90.cigar = quantile(cigar,.90, na.rm = TRUE)
)
View(ps1.compare.records)
error.cigar <- which(ps1.data$cigar == 99)
ps1.data$cigar[error.cigar] <- NA
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar),
per25.cigar = quantile(cigar,.25, na.rm = TRUE),
per75.cigar = quantile(cigar,.75, na.rm = TRUE),
per90.cigar = quantile(cigar,.90, na.rm = TRUE)
)
View(ps1.compare.records)
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar, na.rm = TRUE),
per25.cigar = quantile(cigar,.25, na.rm = TRUE),
per75.cigar = quantile(cigar,.75, na.rm = TRUE),
per90.cigar = quantile(cigar,.90, na.rm = TRUE),
mean.cigar = mean(cigar, na.rm = TRUE)
)
View(ps1.compare.records)
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar, na.rm = TRUE),
per25.cigar = quantile(cigar,.25, na.rm = TRUE),
per75.cigar = quantile(cigar,.75, na.rm = TRUE),
per90.cigar = quantile(cigar,.90, na.rm = TRUE),
mean.cigar = mean(cigar, na.rm = TRUE),
sd.cigar = sd(cigar, na.rm = TRUE)
)
View(ps1.compare.records)
ggplot(ps1.data, aes(x=cigar)) + geom_histogram() + facet_grid(.~full.record)
require(ggplot2)
ggplot(ps1.data, aes(x=cigar)) + geom_histogram() + facet_grid(.~full.record)
ggplot(ps1.data, aes(x=cigar)) + geom_boxplot() + facet_grid(.~full.record)
ggplot(ps1.data, aes(y=cigar)) + geom_boxplot() + facet_grid(.~full.record)
ggplot(ps1.data, aes(cigar)) + geom_boxplot(aes(factor=full.record))
ggplot(ps1.data, aes(cigar)) + geom_boxplot(aes(factor(full.record))
)
ggplot(ps1.data, aes(factor(full.record),cigar)) + geom_boxplot()
ggplot(ps1.data, aes(factor(full.record),cigar)) + geom_boxplot() + ylim(0,15)
ggplot(ps1.data, aes(cigar)) + geom_density() + facet_grid(full.record~.)
ggplot(ps1.data, aes(cigar)) + geom_density() + facet_grid(full.record~.) + xlab("Number of daily cigarettes") + ylab("Density of responses")
ggplot(ps1.data, aes(cigar)) + geom_density() + facet_grid(full.record~.) + xlab("Number of daily cigarettes") + ylab("Density of responses") + ggtitle("TRUE = Full Records Available, FALSE = Missing Records")
pdf(file="/img/cigar-by-record-type.pdf", width = 7, height = 6)
ggplot(ps1.data, aes(cigar)) + geom_density() + facet_grid(full.record~.) + xlab("Number of daily cigarettes") + ylab("Density of responses") + ggtitle("TRUE = Full Records Available, FALSE = Missing Records")
dev.off()
pdf(file="img/cigar-by-record-type.pdf", width = 7, height = 6)
ggplot(ps1.data, aes(cigar)) + geom_density() + facet_grid(full.record~.) + xlab("Number of daily cigarettes") + ylab("Density of responses") + ggtitle("TRUE = Full Records Available, FALSE = Missing Records")
dev.off()
library(car)
attach(Prestige)
detach(Prestige)
data(Prestige)
str(Prestige)
pres <- Prestige
str(pres)
?geom_density
require(ggplot2)
require(plyr)
?geom_density
?density
plot(density(pres$income))
plot(density(pres$income,bw=100))
plot(density(pres$income,bw=500))
plot(density(pres$income,bw=5000))
plot(density(pres$income,bw=50))
plot(density(pres$income,bw=50))
summary(density(pres$income,bw=50))
summary(density(pres$income))
plot(density(pres$income))
plot(density(pres$income, kernel="epanechnikov"))
plot(density(pres$income, kernel="uniform"))
plot(density(pres$income, kernel="rectangular"))
plot(density(pres$income, kernel="g", bw=200))
plot(loess(pres$income))
plot(loess(income ~ education, pres))
?density
require(ggplot2)
require(plyr)
require(np)
install.packages("np")
require(ggplot2)
require(plyr)
require(np)
?np
help.zelig()
require(Zelig)
help.zelig()
help.zelig("models")
?loess
??kern
?auto.arima
??arima
require(forecast)
?auto.arima
average(5, -20)
mean(5,-20)
mean(c(5,-20))
10^10 / 10^6
10^11 / 10^9
?loess
10^9
10*10^9
(10*10^9) / 50
(10*10^9) / 50
100000000
50*300000
50*300000000
x <- c(.04, -.04, -0.06, -.02, -.06)
mean(x)
?t.test
t.test(x)
require(Zelig)
ZeligListModels
ZeligListModels()
help.zelig(zelig)
wsp.z <- zelig(dbrwt ~ tobacco + ns(dmage, df=3) + dmar, data=ps1.data.clean, method = "ls")
wsp.z <- zelig(dbrwt ~ tobacco + ns(dmage, df=3) + dmar, data=ps1.data.clean, model = "ls")
# PROBLEM SET 1B
# ARE 213 Fall 2013
# Frank's Directory
#setwd("/media/frank/Data/documents/school/berkeley/fall13/are213/are213/ps1")
# Peter's Directory
#setwd("~/Google Drive/ERG/Classes/ARE213/are213/ps1")
# Packages --------
library(foreign) #this is to read in Stata data
library(Hmisc)
library(psych)
library(stargazer)
library(ggplot2) # for neato plotting tools
library(plyr) # for nice data tools like ddply
library(epicalc) # For likelihood ratio test
library(car) # "companion for applied regression" - recode fxn, etc.
library(gmodels) #for Crosstabs
library(splines) # for series regression
library(np) #nonparametric regression
library(rms) #regression modeling tools
library(Zelig)
# Homebrewed functions
source("../util/are213-func.R")
source("../util/watercolor.R") # for watercolor plots
# Data -------
ps1.data <- read.dta(file="ps1.dta")
var.labels <- attr(ps1.data, "var.labels")
# Data Cleaning Step
full.record.flag <- which(ps1.data$cardiac != 9 &
ps1.data$cardiac != 8 &
ps1.data$lung != 9 &
ps1.data$lung != 8 &
ps1.data$diabetes !=9 &
ps1.data$diabetes !=8 &
ps1.data$herpes != 9 &
ps1.data$herpes != 8 &
ps1.data$chyper != 9 &
ps1.data$chyper != 8 &
ps1.data$phyper != 9 &
ps1.data$phyper != 8 &
ps1.data$pre4000 !=9 &
ps1.data$pre4000 !=8 &
ps1.data$preterm != 9 &
ps1.data$preterm != 8 &
ps1.data$tobacco != 9 &
ps1.data$cigar != 99 &
ps1.data$cigar6 !=6 &
ps1.data$alcohol != 9 &
ps1.data$drink != 99 &
ps1.data$drink5 !=5 &
ps1.data$wgain !=99
)
ps1.data$full.record <- FALSE # initialize column as F
ps1.data$full.record[full.record.flag] <- TRUE #reassign level to T for full records
ps1.data.clean <- subset (ps1.data, full.record == TRUE)
ps1.data.missingvalues <- subset(ps1.data, full.record == FALSE)
# Problem 1a : Describes PS1a results. -------
# Problem 1b --------------
# This is using a series estimator. I think smooth.spline() is the right function to use, but let me know if you think we should be doing kernel regression instead. I'm also not sure how to go about adding interaction terms.  I think a kernel regression is more appropriate here...mostly because I don't know the spline function and there seems to be a good package ("np") for running kernel regression.
wsp.z <- zelig(dbrwt ~ tobacco + ns(dmage, df=3) + dmar, data=ps1.data.clean, model = "ls")
# Data -------
ps1.data <- read.dta(file="ps1.dta")
var.labels <- attr(ps1.data, "var.labels")
# Data Cleaning Step
full.record.flag <- which(ps1.data$cardiac != 9 &
ps1.data$cardiac != 8 &
ps1.data$lung != 9 &
ps1.data$lung != 8 &
ps1.data$diabetes !=9 &
ps1.data$diabetes !=8 &
ps1.data$herpes != 9 &
ps1.data$herpes != 8 &
ps1.data$chyper != 9 &
ps1.data$chyper != 8 &
ps1.data$phyper != 9 &
ps1.data$phyper != 8 &
ps1.data$pre4000 !=9 &
ps1.data$pre4000 !=8 &
ps1.data$preterm != 9 &
ps1.data$preterm != 8 &
ps1.data$tobacco != 9 &
ps1.data$cigar != 99 &
ps1.data$cigar6 !=6 &
ps1.data$alcohol != 9 &
ps1.data$drink != 99 &
ps1.data$drink5 !=5 &
ps1.data$wgain !=99
)
ps1.data$full.record <- FALSE # initialize column as F
ps1.data$full.record[full.record.flag] <- TRUE #reassign level to T for full records
ps1.data.clean <- subset (ps1.data, full.record == TRUE)
ps1.data.missingvalues <- subset(ps1.data, full.record == FALSE)
setwd("~/Google Drive/ERG/Classes/ARE213/are213/ps1")
# Packages --------
library(foreign) #this is to read in Stata data
library(Hmisc)
library(psych)
library(stargazer)
library(ggplot2) # for neato plotting tools
library(plyr) # for nice data tools like ddply
library(epicalc) # For likelihood ratio test
library(car) # "companion for applied regression" - recode fxn, etc.
library(gmodels) #for Crosstabs
library(splines) # for series regression
library(np) #nonparametric regression
library(rms) #regression modeling tools
library(Zelig)
# Homebrewed functions
source("../util/are213-func.R")
source("../util/watercolor.R") # for watercolor plots
# Data -------
ps1.data <- read.dta(file="ps1.dta")
var.labels <- attr(ps1.data, "var.labels")
# Data Cleaning Step
full.record.flag <- which(ps1.data$cardiac != 9 &
ps1.data$cardiac != 8 &
ps1.data$lung != 9 &
ps1.data$lung != 8 &
ps1.data$diabetes !=9 &
ps1.data$diabetes !=8 &
ps1.data$herpes != 9 &
ps1.data$herpes != 8 &
ps1.data$chyper != 9 &
ps1.data$chyper != 8 &
ps1.data$phyper != 9 &
ps1.data$phyper != 8 &
ps1.data$pre4000 !=9 &
ps1.data$pre4000 !=8 &
ps1.data$preterm != 9 &
ps1.data$preterm != 8 &
ps1.data$tobacco != 9 &
ps1.data$cigar != 99 &
ps1.data$cigar6 !=6 &
ps1.data$alcohol != 9 &
ps1.data$drink != 99 &
ps1.data$drink5 !=5 &
ps1.data$wgain !=99
)
ps1.data$full.record <- FALSE # initialize column as F
ps1.data$full.record[full.record.flag] <- TRUE #reassign level to T for full records
ps1.data.clean <- subset (ps1.data, full.record == TRUE)
ps1.data.missingvalues <- subset(ps1.data, full.record == FALSE)
# Problem 1a : Describes PS1a results. -------
# Problem 1b --------------
# This is using a series estimator. I think smooth.spline() is the right function to use, but let me know if you think we should be doing kernel regression instead. I'm also not sure how to go about adding interaction terms.  I think a kernel regression is more appropriate here...mostly because I don't know the spline function and there seems to be a good package ("np") for running kernel regression.
wsp.z <- zelig(dbrwt ~ tobacco + ns(dmage, df=3) + dmar, data=ps1.data.clean, model = "ls")
sim(wsp.z)
setx(obj=wsp.z,data=data.frame(tobacco = 2))
setx(obj=wsp.z)
setx(obj=wsp.z)->wsp.set
sim(wsp.z, wsp.set)
wsp.set(wsp.z, tobacco = 2)
wsp.set<-setx(wsp.z, tobacco = 2)
s.out <- sim(wsp.z, wsp.set)
plot(wsp.z)
summary(wsp.z)
levels(ps1.data.clean$tobacco)
class(ps1.data.clean$tobacco)
ps1.data.clean$tobacco <- as.factor(ps1.data.clean$tobacco)
ps1.data.clean$dmar <- as.factor(ps1.data.clean$dmar)
wsp.z <- zelig(dbrwt ~ tobacco + ns(dmage, df=3) + dmar, data=ps1.data.clean, model = "ls")
wsp.set <- setx(wsp.z, tobacco = 2)
wsp.set1 <- setx(wsp.z, tobacco = 1)
summary(wsp.set)
summary(wsp.set1)
sim(wsp.z, x=wsp.set, x1 = wsp.set1)
sim
require(Zelig)
library(Zelig)
siom
sim
detatch(psych)
?detatch
detach(psych)
detach("psych")
detach("package:psych", unload=TRUE)
sim(wsp.z, wsp.set, wsp.set1)
