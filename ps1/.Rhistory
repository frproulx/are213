activeDay <- start
#define base URL
baseURL <- "http://oasis.caiso.com/mrtu-oasis/SingleZip?"
# First day -- initialize data output frame with first data.
getURL <- paste(baseURL,"resultformat=6&queryname=SLD_FCST&startdate=",strftime(activeDay,"%Y%m%d"),"&enddate=",strftime(activeDay,"%Y%m%d"),sep="")
temp <- tempfile() #create temp file
try(download.file(getURL,temp)) # get data into temp
try(data <- read.csv(unzip(temp)))
unlink(temp)
activeDay <- activeDay + 86400 # add one day (in seconds)
# Subsequent days -- download and append
while(activeDay < end){
getURL <- paste(baseURL,"resultformat=6&queryname=SLD_FCST&startdate=",strftime(activeDay,"%Y%m%d"),"&enddate=",strftime(activeDay,"%Y%m%d"),sep="")
temp <- tempfile() #create temp file
try(download.file(getURL,temp)) # get data into temp
try(newdata <- read.csv(unzip(temp))) # unzip and read csv, dump into data
unlink(temp)
try(data <- rbind(data,newdata))#append new data to existing
activeDay <- activeDay + 86400 # add one day (in seconds)
} #end while loop for moving through time...
return(data) # these are the data you are looking for...
} #end FUNCTION ... getCAISOload
# Fetch CAISO public bid data (be careful, these are big files)
getCAISObids <- function(startdate=20110101, enddate=20110102, market="DAM"){
#market is DAM or RTM
# this function simply grabs the csv data from caiso and dumps it into a data frame with the same structure as the csv.
# convert CAISO format to POSIXct dates
start <- strptime(startdate,"%Y%m%d")
end <- strptime(enddate,"%Y%m%d")
# Initialize data frame with starting day
activeDay <- start
#define base URL
baseURL <- "http://oasis.caiso.com/mrtu-oasis/GroupZip?" #note this is a grouped file
reportname<-paste("PUB_",market,"_GRP",sep="")
# First day -- initialize data output frame with first data.
getURL <- paste(baseURL,"resultformat=6&groupid=",reportname,"&startdate=",strftime(activeDay,"%Y%m%d"),sep="")
temp <- tempfile() #create temp file
try(download.file(getURL,temp)) # get data into temp
try(data <- read.csv(unzip(temp)))
unlink(temp)
activeDay <- activeDay + 86400 # add one day (in seconds)
# Subsequent days -- download and append
while(activeDay < end){
getURL <- paste(baseURL,"resultformat=6&groupid=",reportname,"&startdate=",strftime(activeDay,"%Y%m%d"),sep="")
temp <- tempfile() #create temp file
try(download.file(getURL,temp)) # get data into temp
try(newdata <- read.csv(unzip(temp))) # unzip and read csv, dump into data
unlink(temp)
try(data <- rbind(data,newdata))#append new data to existing
activeDay <- activeDay + 86400 # add one day (in seconds)
} #end while loop for moving through time...
return(data) # these are the data you are looking for...
} #end FUNCTION ... getCAISObids
# Fetch CAISO public bid data (be careful, these are big files)
getCAISOopres <- function(startdate=20110101, enddate=20110102){
#market is DAM or RTM
# this function simply grabs the csv data from caiso and dumps it into a data frame with the same structure as the csv.
# convert CAISO format to POSIXct dates
start <- strptime(startdate,"%Y%m%d")
end <- strptime(enddate,"%Y%m%d")
# Initialize data frame with starting day
activeDay <- start
#define base URL
baseURL <- "http://oasis.caiso.com/mrtu-oasis/SingleZip?" #note this is a grouped file
# First day -- initialize data output frame with first data.
getURL <- paste(baseURL,"resultformat=6&queryname=AS_OP_RSRV&startdate=",strftime(activeDay,"%Y%m%d"),"&enddate=",strftime(activeDay,"%Y%m%d"),sep="")
temp <- tempfile() #create temp file
try(download.file(getURL,temp)) # get data into temp
try(data <- read.csv(unzip(temp)))
unlink(temp)
activeDay <- activeDay + 86400 # add one day (in seconds)
# Subsequent days -- download and append
while(activeDay < end){
getURL <- paste(baseURL,"resultformat=6&queryname=AS_OP_RSRV&startdate=",strftime(activeDay,"%Y%m%d"),"&enddate=",strftime(activeDay,"%Y%m%d"),sep="")
temp <- tempfile() #create temp file
try(download.file(getURL,temp)) # get data into temp
try(newdata <- read.csv(unzip(temp))) # unzip and read csv, dump into data
unlink(temp)
try(data <- rbind(data,newdata))#append new data to existing
activeDay <- activeDay + 86400 # add one day (in seconds)
} #end while loop for moving through time...
return(data) # these are the data you are looking for...
} #end FUNCTION ... getCAISOopres
# add date info to CAISO data frames
addDatesCAISO <- function(caisodata,date.format=c("%Y%m%d"),date.column="OPR_DT"){
caisodata$posixlt <- as.POSIXlt(caisodata[[date.column]])
caisodata$year <- caisodata$posixlt$year+1900
caisodata$mon <- strftime(caisodata$posixlt,"%b")
caisodata$monnum <-strftime(caisodata$posixlt,"%m")
caisodata$mday <- caisodata$posixlt$mday
caisodata$wday <- strftime(caisodata$posixlt,"%a") #week day
caisodata$date <- strftime(caisodata$posixlt,date.format)
caisodata$yhr <- caisodata$posixlt$yday*24+caisodata$posixlt$hour+1 #hour ending 1-8760 over the year
caisodata$yday <- caisodata$posixlt$yday
return(caisodata)
}
# melt CAISO data into a mono-value data frame for analysis.
meltCAISO <- function(caisodata,preserve.na=FALSE){
hourLabels <- c("HE01","HE02","HE03","HE04","HE05","HE06","HE07","HE08","HE09","HE10","HE11","HE12","HE13","HE14","HE15","HE16","HE17","HE18","HE19","HE20","HE21","HE22","HE23","HE24")
data <- melt(caisodata,id=which(!names(caisodata) %in% hourLabels),measured=which(names(caisodata) %in% hourLabels,na.rm=preserve.na))
return(data)
}
# Load duration curves with classic R look saved to pdf
makeLDC<-function(data,value.column,file="mypdf.pdf",
h=5,w=10,
xlab="Exceedance (unitless)",ylab="value",
main="Load Duration Curve",sub="CAISO total service area",type="p"){
data<-arrange(data,desc(data[[value.column]]))
pdf(file,width=w,height=h)
cumdist <- 1:length(data[[value.column]]) / length(data[[value.column]])
myplot<-plot(cumdist,data[[value.column]],xlab=xlab,ylab=ylab,main=main,sub=sub,type=type)
print(myplot)
dev.off()}
# Load duration curves with classic R look ready to send to a graphics device.
viewLDC<-function(data,value.column,
color, #use same number of colors as value column!
h=5,w=10,
xlab="Exceedance (unitless)",ylab="value",
main="Load Duration Curve",sub="CAISO total service area",type="p"){
if(length(value.column)==1){
# for first value column
data<-arrange(data,desc(data[[value.column]]))
cumdist <- 1:length(data[[value.column]]) / length(data[[value.column]])
myplot<-plot(cumdist,data[[value.column]],col=color[1],xlab=xlab,ylab=ylab,main=main,sub=sub,type=type)
return(myplot)
}else{
# for first value column initialize plot
active.data<-arrange(data,desc(data[[value.column[1]]]))
cumdist <- 1:length(active.data[[value.column[1]]]) / length(active.data[[value.column[1]]])
myplot<-plot(cumdist,active.data[[value.column[1]]],col=color[1],xlab=xlab,ylab=ylab,main=main,sub=sub,type=type)
for(i in 2:length(value.column)){
active.data<-arrange(data,desc(data[[value.column[i]]]))
cumdist <- 1:length(active.data[[value.column[i]]]) / length(active.data[[value.column[i]]])
points(cumdist,active.data[[value.column[i]]],col=color[i])
}
return(myplot)
}}#end function view LDC
# add temporal categories (useful for slicing up data by season / peak / weekend)
addTimeCats <- function(data,time.column="posixlt",hour.column="dhr"){
begin.summer <- 5 #first month of summer
end.summer <- 9 #last month of summer
begin.peak.sum <- 13 # first hour on peak
end.peak.sum <- 19 # last hour on peak
begin.peak.wint <- 17
end.peak.wint <- 20
for(i in 1:length(data[[time.column]])){
month <- data[[time.column]][["mon"]][i]+1
hour <- data[[hour.column]][i]
day <- data[[time.column]][["wday"]][i]
season <- if(month <= begin.summer | month >= end.summer){"winter"}else{"summer"}
daytype <- if(day==0 | day==6){"weekend"}else{"weekday"}
period <- if(daytype=="weekend"){"off.peak"}else{if(season == "summer" & begin.peak.sum <= hour & hour <= end.peak.sum){"peak"}else{if(season == "winter" & begin.peak.wint <= hour & hour <= end.peak.wint){"peak"}else{"off.peak"}}}
data$season[i] <- season
data$period[i] <- period
data$daytype[i] <- daytype
}
return(data)
}
# Arrange ggplots (appropriated from http://gettinggeneticsdone.blogspot.com/2010/03/arrange-multiple-ggplot2-plots-in-same.html)
vp.layout <- function(x, y) viewport(layout.pos.row=x, layout.pos.col=y)
arrange_ggplot2 <- function(..., nrow=NULL, ncol=NULL, as.table=FALSE) {
dots <- list(...)
n <- length(dots)
if(is.null(nrow) & is.null(ncol)) { nrow = floor(n/2) ; ncol = ceiling(n/nrow)}
if(is.null(nrow)) { nrow = ceiling(n/ncol)}
if(is.null(ncol)) { ncol = ceiling(n/nrow)}
## NOTE see n2mfrow in grDevices for possible alternative
grid.newpage()
pushViewport(viewport(layout=grid.layout(nrow,ncol) ) )
ii.p <- 1
for(ii.row in seq(1, nrow)){
ii.table.row <- ii.row
if(as.table) {ii.table.row <- nrow - ii.table.row + 1}
for(ii.col in seq(1, ncol)){
ii.table <- ii.p
if(ii.p > n) break
print(dots[[ii.table]], vp=vp.layout(ii.table.row, ii.col))
ii.p <- ii.p + 1
}
}
}
# Calculate DR payment (NOTE: Electricity savings potential ests are broken somehow...too high in some random cases...)
dr.payment <- function(LMP,nbt.threshold,potential,load.shape,retail.elec,only.during.nbt=FALSE){
# LMP is a vector of LMP for the time period
# nbt.threshold is a vector of nbt threshold times for the period (or a single value)
# mw.potential is the maximum savings potential for the measure (a single value)
# load shape is a vector of relative availability for the measure--fractions of peak (in time)
# retail.elec is either a vector of prices or a single value
timesteps <- length(LMP)
if(length(nbt.threshold==1)){nbt.threshold <- matrix(nbt.threshold,nrow=timesteps)}
if(length(retail.elec==1)){retail.elec <- matrix(retail.elec,nrow=timesteps)}
if(length(load.shape)!=timesteps){stop("load shape different length than lmp")}
potential <- potential*load.shape
# make dr payment matrix with zeroes if < nbt and lMP if > nbt.
dr.payment <- matrix(data=0,nrow=timesteps)
pass.nbt <- which(LMP>=nbt.threshold)
fail.nbt <- which(LMP<nbt.threshold)
dr.payment[pass.nbt]<-LMP[pass.nbt]
if(only.during.nbt){retail.elec[fail.nbt]<-0}
dr.rev <- dr.payment*potential
e.save <- retail.elec*potential
tot <- dr.rev + e.save
out<-data.frame(dr.rev=dr.rev,e.save=e.save,tot=tot)
} #end function dr.payment
getCAISObids(startdate=20120101,enddate=20120102)->bids
rstudio::viewData(bids)
getCAISObids
getCAISObids(startdate=20120101,enddate=20120102,market="RTM")->bidr
names(bidr)
hist(bidr$STARTTIME)
class(bidr.STARTTIME)
class(bidr$STARTTIME)
hist(as.numeric((bidr$STARTTIME))
)
head(bidr)
read.csv("Downloads/ladb-test-results-final.csv")->t
names(t)
require(plyr)
tt <- ddply(.data=t, .variables=c(product_name, date_began), .fun=summary, srt=mean(solar.runtime.measured))
tt <- ddply(.data=t, .variables=c("product_name", "date_began"), .fun=summary, srt=mean(solar.runtime.measured))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar.runtime.measured))
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean("solar.runtime.measured"))
rstudio::viewData(tt)
warnings()
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar.runtime.measured))
tt <- ddply(.data=t, .variables=c("product_name", "date_began"), summarize, srt=mean(solar.runtime.measured))
names(t)
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar_runtime_measured))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n=count(solar_runtime_measured, na.rm=TRUE))
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n=count(solar_runtime_measured))
count(c(1,2,3,4))
length(c(1,2,3,4))
?length
tt <- ddply(t, .(product_name, date_began), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n=length(solar_runtime_measured))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began, setting), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n.srt=length(solar_runtime_measured), lm=mean(runtime_flux_70))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began, setting), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n.srt=length(solar_runtime_measured), lm=mean(runtime_flux_70, na.rm=TRUE))
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began, setting), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n.srt=length(solar_runtime_measured), lm.run=mean(runtime_flux_70, na.rm=TRUE), lm.nom=mean(nominal_lumin_flux), na.rm=TRUE)
rstudio::viewData(tt)
tt <- ddply(t, .(product_name, date_began, setting), summarize, srt=mean(solar_runtime_measured,na.rm=TRUE), n.srt=length(solar_runtime_measured), lm.run=mean(runtime_flux_70, na.rm=TRUE), lm.nom=mean(nominal_lumin_flux, na.rm=TRUE))
rstudio::viewData(tt)
min(NaN, 2)
min(NaN, 2, na.rm=TRUE)
tt$lm <- min(lm.run, lm.nom, na.rm=TRUE)
tt$lm <- min(tt$lm.run, tt$lm.nom, na.rm=TRUE)
rstudio::viewData(tt)
tt$lm <- min(tt$lm.run, tt$lm.nom)
hist(tt$lm)
?min
min(c(1,2,3,4), c(2,3,4,5))
tt$lm <- pmin(tt$lm.run, tt$lm.nom, na.rm=TRUE)
rstudio::viewData(tt)
tt$lmhr <- tt$lm*tt$srt
hist(tt$lmhr)
plot(ecdf(tt$lmhr))
setwd("~/Google Drive/ERG/Classes/ARE213/are213/ps1")
library(foreign) #this is to read in Stata data
library(Hmisc)
library(psych)
data <- read.dta("ps1.dta")
require(Hmisc)
install.packages(c("Hmisc", "psych"))
library(foreign) #this is to read in Stata data
library(Hmisc)
library(psych)
data <- read.dta("ps1.dta")
print(nrow(ps1.data))
## Problem 1a: Fix miss
ps1.data <- read.dta("ps1.dta") #changed name of object from "data" to avoid ambiguity issues since "data" is often embedded in functions as a general object
print(nrow(ps1.data))
## Problem 1a: Fix mis
ps1.data <- subset (ps1.data, (cardiac != 9) & (lung != 9) & (diabetes !=9) & (herpes !=9) & (chyper !=9) & (phyper !=9) & (pre4000 !=9) & (preterm !=9) & (tobacco !=9) & (cigar !=99) & (cigar6 !=6) & (alcohol !=9) & (drink !=99) & (drink5 !=5) & (wgain !=99))
print(nrow(ps1.data)) #number of records remaining after cleaning
?subset
attach(ps1.data)
detach(name=ps1.data)
wgain %in% names(ps1.data)
"wgain" %in% names(ps1.data)
?match
match("wgain", names(ps1.data))
match("alcohol", names(ps1.data))
full.record.flag <- which(ps1.data$cardiac != 9 & ps1.data$lung != 9 & ps1.data$diabetes !=9 & ps1.data$herpes != 9 & ps1.data$chyper != 9 & ps1.data$phyper != 9 & ps1.data$pre4000 !=9 & ps1.data$preterm != 9 & ps1.data$tobacco != 9 & ps1.data$cigar != 99 & ps1.data$cigar6 !=6 & ps1.data$alcohol != 9 & ps1.data$drink != 99 & ps1.data$drink5 !=5 & ps1.data$wgain !=99)
head(full.record.flag)
ps1.data$full.record <- FALSE # initialize column as F
ps1.data$full.record[full.record.flag] <- TRUE #reassign level to T for full records
head(ps1.data)
View(ps1.data)
ps1.data.clean <- subset (ps1.data, full.record == TRUE)
ps1.data <- read.dta("ps1.dta") #changed name of object from "data" to avoid ambiguity issues since "data" is often embedded in functions as a general object
print(nrow(ps1.data))
## Problem 1a: Fix missing values
## The following are the error codes for each of the 15 variables that need fixing:
# cardiac: 9
# lung: 9
# diabetes: 9
# herpes: 9
# chyper: 9
# phyper: 9
# pre4000: 9
# preterm: 9
# tobacco: 9
# cigar: 99
# cigar6: 6
# alcohol: 9
# drink: 99
# drink5: 5
# wgain: 99
# Identify which records have full data, then add a column to indicate full records or not.
full.record.flag <- which(ps1.data$cardiac != 9 & ps1.data$lung != 9 & ps1.data$diabetes !=9 & ps1.data$herpes != 9 & ps1.data$chyper != 9 & ps1.data$phyper != 9 & ps1.data$pre4000 !=9 & ps1.data$preterm != 9 & ps1.data$tobacco != 9 & ps1.data$cigar != 99 & ps1.data$cigar6 !=6 & ps1.data$alcohol != 9 & ps1.data$drink != 99 & ps1.data$drink5 !=5 & ps1.data$wgain !=99)
ps1.data$full.record <- FALSE # initialize column as F
ps1.data$full.record[full.record.flag] <- TRUE #reassign level to T for full records
ps1.data.clean <- subset (ps1.data, full.record == TRUE)
summarytable<-print(describe(ps1.data.clean, skew=FALSE, ranges=FALSE))
ps1.data.missingvalues <- subset(ps1.data, full.record == FALSE)
require(gdata)
install.packages(gdata)
install.packages("gdata")
aggregate.table(ps1.data, full.record, FUN="mean")
require(gdata)
aggregate.table(ps1.data, full.record, FUN="mean")
aggregate.table(ps1.data, "full.record", FUN="mean")
aggregate.table(ps1.data, "full.record", FUN="mean")
write.csv(ps1.data.clean, file = "ps1dataclean.csv")
?compare
nalysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .full.record, summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps))
require(ddply)
require(plyr)
nalysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .full.record, summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps))
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps))
View(ps1.compare.records)
# compare records on things that matter for this analysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
mean.cigar = mean(cigar),
sd.cigar = sd(cigar))
View(ps1.compare.records)
hist(ps1.data.missingvalues$cigar)
# compare records on things that matter for this analysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar)
)
View(ps1.compare.records)
?quantile
# compare records on things that matter for this analysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar),
per25.cigar = quantile(cigar,.25, na.rm = TRUE)
)
View(ps1.compare.records)
# compare records on things that matter for this analysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar),
per25.cigar = quantile(cigar,.25, na.rm = TRUE),
per75.cigar = quantile(cigar,.75, na.rm = TRUE),
per90.cigar = quantile(cigar,.90, na.rm = TRUE),
)
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar),
per25.cigar = quantile(cigar,.25, na.rm = TRUE),
per75.cigar = quantile(cigar,.75, na.rm = TRUE),
per90.cigar = quantile(cigar,.90, na.rm = TRUE)
)
View(ps1.compare.records)
error.cigar <- which(ps1.data$cigar == 99)
ps1.data$cigar[error.cigar] <- NA
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar),
per25.cigar = quantile(cigar,.25, na.rm = TRUE),
per75.cigar = quantile(cigar,.75, na.rm = TRUE),
per90.cigar = quantile(cigar,.90, na.rm = TRUE)
)
View(ps1.compare.records)
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar, na.rm = TRUE),
per25.cigar = quantile(cigar,.25, na.rm = TRUE),
per75.cigar = quantile(cigar,.75, na.rm = TRUE),
per90.cigar = quantile(cigar,.90, na.rm = TRUE),
mean.cigar = mean(cigar, na.rm = TRUE)
)
View(ps1.compare.records)
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
median.cigar = median(cigar, na.rm = TRUE),
per25.cigar = quantile(cigar,.25, na.rm = TRUE),
per75.cigar = quantile(cigar,.75, na.rm = TRUE),
per90.cigar = quantile(cigar,.90, na.rm = TRUE),
mean.cigar = mean(cigar, na.rm = TRUE),
sd.cigar = sd(cigar, na.rm = TRUE)
)
View(ps1.compare.records)
ggplot(ps1.data, aes(x=cigar)) + geom_histogram() + facet_grid(.~full.record)
require(ggplot2)
ggplot(ps1.data, aes(x=cigar)) + geom_histogram() + facet_grid(.~full.record)
ggplot(ps1.data, aes(x=cigar)) + geom_boxplot() + facet_grid(.~full.record)
ggplot(ps1.data, aes(y=cigar)) + geom_boxplot() + facet_grid(.~full.record)
ggplot(ps1.data, aes(cigar)) + geom_boxplot(aes(factor=full.record))
ggplot(ps1.data, aes(cigar)) + geom_boxplot(aes(factor(full.record))
)
ggplot(ps1.data, aes(factor(full.record),cigar)) + geom_boxplot()
ggplot(ps1.data, aes(factor(full.record),cigar)) + geom_boxplot() + ylim(0,15)
ggplot(ps1.data, aes(cigar)) + geom_density() + facet_grid(full.record~.)
ggplot(ps1.data, aes(cigar)) + geom_density() + facet_grid(full.record~.) + xlab("Number of daily cigarettes") + ylab("Density of responses")
ggplot(ps1.data, aes(cigar)) + geom_density() + facet_grid(full.record~.) + xlab("Number of daily cigarettes") + ylab("Density of responses") + ggtitle("TRUE = Full Records Available, FALSE = Missing Records")
pdf(file="/img/cigar-by-record-type.pdf", width = 7, height = 6)
ggplot(ps1.data, aes(cigar)) + geom_density() + facet_grid(full.record~.) + xlab("Number of daily cigarettes") + ylab("Density of responses") + ggtitle("TRUE = Full Records Available, FALSE = Missing Records")
dev.off()
pdf(file="img/cigar-by-record-type.pdf", width = 7, height = 6)
ggplot(ps1.data, aes(cigar)) + geom_density() + facet_grid(full.record~.) + xlab("Number of daily cigarettes") + ylab("Density of responses") + ggtitle("TRUE = Full Records Available, FALSE = Missing Records")
dev.off()
?latex
library(foreign) #this is to read in Stata data
library(Hmisc)
library(psych)
library(stargazer)
library(ggplot2) # for neato plotting tools
library(plyr) # for nice data tools
?latex
setwd("~/Google Drive/ERG/Classes/ARE213/are213/ps1")
ps1.data <- read.dta(file="ps1.dta")
#changed name of object from "data" to avoid ambiguity issues since "data" is often embedded in functions as a general object
print(nrow(ps1.data))
## Problem 1a: Fix missing values --------
## The following are the error codes for each of the 15 variables that need fixing:
# cardiac: 9
# lung: 9
# diabetes: 9
# herpes: 9
# chyper: 9
# phyper: 9
# pre4000: 9
# preterm: 9
# tobacco: 9
# cigar: 99
# cigar6: 6
# alcohol: 9
# drink: 99
# drink5: 5
# wgain: 99
# Identify which records have full data, then add a column to indicate full records or not.
full.record.flag <- which(ps1.data$cardiac != 9 & ps1.data$lung != 9 & ps1.data$diabetes !=9 & ps1.data$herpes != 9 & ps1.data$chyper != 9 & ps1.data$phyper != 9 & ps1.data$pre4000 !=9 & ps1.data$preterm != 9 & ps1.data$tobacco != 9 & ps1.data$cigar != 99 & ps1.data$cigar6 !=6 & ps1.data$alcohol != 9 & ps1.data$drink != 99 & ps1.data$drink5 !=5 & ps1.data$wgain !=99)
ps1.data$full.record <- FALSE # initialize column as F
ps1.data$full.record[full.record.flag] <- TRUE #reassign level to T for full records
# replace error rows in cigar with NA so they don't interfere with other calcs.
error.cigar <- which(ps1.data$cigar == 99)
ps1.data$cigar[error.cigar] <- NA
# compare records on things that matter for this analysis...apgar, smoking, etc.
ps1.compare.records <- ddply(ps1.data, .(full.record), summarize,
mean.omaps = mean(omaps),
sd.omaps = sd(omaps),
mean.fmaps = mean(fmaps),
sd.fmaps = sd(fmaps),
mean.cigar = mean(cigar, na.rm = TRUE),
sd.cigar = sd(cigar, na.rm = TRUE)
)
stargazer(ps1.compare.records, type="text")
?summarize
summarize(ps1.compare.records)
stargazer(ps1.compare.records, type="text", summary=FALSE)
save(stargazer(ps1.compare.records, summary=FALSE), file="table-missingDataCompare.tex")
stargazer(ps1.compare.records, summary=FALSE)
# Linear model to see if you can predict whether the data have a full record based on cigar, omaps, fmaps
unclean.cig <- lm(full.record ~ cigar, ps1.data)
unclean.cig.om <- lm(full.record ~ omaps + cigar, ps1.data)
unclean.cig.om.fm <- lm(full.record ~ omaps + fmaps + cigar, ps1.data)
# The models seem to indicate you can predict whether there is a full record based on apgar and cigarette use....unfortunate.
stargazer(unclean.cig, unclean.cig.om, unclean.cig.om.fm, type="text")
stargazer(unclean.cig.om.fm)
stargazer(unclean.cig.om.fm, out="table-fullData-lmResults.tex")
